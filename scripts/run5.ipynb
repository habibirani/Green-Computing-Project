{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E8cHH8e9Cg1C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil  # https://docs.python.org/3/library/shutil.html\n",
        "from shutil import unpack_archive  # to unzip\n",
        "# from shutil import make_archive # to create zip for storage\n",
        "import requests  # for downloading zip file\n",
        "from scipy import io  # for loadmat, matlab conversion\n",
        "import numpy as np\n",
        "\n",
        "# credit https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url\n",
        "# many other methods I tried failed to download the file properly\n",
        "\n",
        "\n",
        "def download_url(url, save_path, chunk_size=128):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            fd.write(chunk)\n",
        "\n",
        "\n",
        "def unimib_load_dataset(\n",
        "        verbose=True,\n",
        "        incl_xyz_accel=False,  # include component accel_x/y/z in ____X data\n",
        "        # add rms value (total accel) of accel_x/y/z in ____X data\n",
        "        incl_rms_accel=True,\n",
        "        incl_val_group=False,  # True => returns x/y_test, x/y_validation, x/y_train\n",
        "    # False => combine test & validation groups\n",
        "        split_subj=dict\n",
        "    (train_subj=[4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 19, 20, 21, 22, 24, 26, 27, 29],\n",
        "     validation_subj=[1, 9, 16, 23, 25, 28],\n",
        "     test_subj=[2, 3, 13, 17, 18, 30]),\n",
        "        one_hot_encode=True):\n",
        "\n",
        "    # Download and unzip original dataset\n",
        "    if (not os.path.isfile('./UniMiB-SHAR.zip')):\n",
        "        print(\"Downloading UniMiB-SHAR.zip file\")\n",
        "        # invoking the shell command fails when exported to .py file\n",
        "        # redirect link https://www.dropbox.com/s/raw/x2fpfqj0bpf8ep6/UniMiB-SHAR.zip\n",
        "        #!wget https://www.dropbox.com/s/x2fpfqj0bpf8ep6/UniMiB-SHAR.zip\n",
        "        download_url(\n",
        "            'https://www.dropbox.com/s/raw/x2fpfqj0bpf8ep6/UniMiB-SHAR.zip', './UniMiB-SHAR.zip')\n",
        "    if (not os.path.isdir('./UniMiB-SHAR')):\n",
        "        shutil.unpack_archive('./UniMiB-SHAR.zip', '.', 'zip')\n",
        "    # Convert .mat files to numpy ndarrays\n",
        "    path_in = './UniMiB-SHAR/data'\n",
        "    # loadmat loads matlab files as dictionary, keys: header, version, globals, data\n",
        "    adl_data = io.loadmat(path_in + '/adl_data.mat')['adl_data']\n",
        "    adl_names = io.loadmat(path_in + '/adl_names.mat',\n",
        "                           chars_as_strings=True)['adl_names']\n",
        "    adl_labels = io.loadmat(path_in + '/adl_labels.mat')['adl_labels']\n",
        "\n",
        "    # Reshape data and compute total (rms) acceleration\n",
        "    num_samples = 151\n",
        "    # UniMiB SHAR has fixed size of 453 which is 151 accelX, 151 accely, 151 accelz\n",
        "    adl_data = np.reshape(adl_data, (-1, num_samples, 3),\n",
        "                          order='F')  # uses Fortran order\n",
        "    if (incl_rms_accel):\n",
        "        rms_accel = np.sqrt(\n",
        "            (adl_data[:, :, 0]**2) + (adl_data[:, :, 1]**2) + (adl_data[:, :, 2]**2))\n",
        "        adl_data = np.dstack((adl_data, rms_accel))\n",
        "\n",
        "    # remove component accel if needed\n",
        "    if (not incl_xyz_accel):\n",
        "        adl_data = np.delete(adl_data, [0, 1, 2], 2)\n",
        "\n",
        "    # matlab source was 1 indexed, change to 0 indexed\n",
        "    act_num = (adl_labels[:, 0])-1\n",
        "    sub_num = (adl_labels[:, 1])  # subject numbers are in column 1 of labels\n",
        "\n",
        "    if (not incl_val_group):\n",
        "        train_index = np.nonzero(np.isin(sub_num, split_subj['train_subj'] +\n",
        "                                         split_subj['validation_subj']))\n",
        "        x_train = adl_data[train_index]\n",
        "        y_train = act_num[train_index]\n",
        "    else:\n",
        "        train_index = np.nonzero(np.isin(sub_num, split_subj['train_subj']))\n",
        "        x_train = adl_data[train_index]\n",
        "        y_train = act_num[train_index]\n",
        "\n",
        "        validation_index = np.nonzero(\n",
        "            np.isin(sub_num, split_subj['validation_subj']))\n",
        "        x_validation = adl_data[validation_index]\n",
        "        y_validation = act_num[validation_index]\n",
        "\n",
        "    test_index = np.nonzero(np.isin(sub_num, split_subj['test_subj']))\n",
        "    x_test = adl_data[test_index]\n",
        "    y_test = act_num[test_index]\n",
        "\n",
        "    if (verbose):\n",
        "        print(\"x/y_train shape \", x_train.shape, y_train.shape)\n",
        "    if (incl_val_group):\n",
        "        print(\"x/y_validation shape \", x_validation.shape, y_validation.shape)\n",
        "    print(\"x/y_test shape  \", x_test.shape, y_test.shape)\n",
        "\n",
        "    if (incl_val_group):\n",
        "        return x_train, y_train, x_validation, y_validation, x_test, y_test\n",
        "    else:\n",
        "        return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_valid, y_valid, X_test, y_test = unimib_load_dataset(\n",
        "    incl_xyz_accel=True, incl_val_group=True, one_hot_encode=False, verbose=True\n",
        ")\n",
        "\n",
        "# Number of classes\n",
        "n_classes = len(np.unique(y_train))\n",
        "print(f\"Number of classes: {n_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYSBW_gKCnu4",
        "outputId": "fe3d1301-82a8-4b03-d8ad-68ad2131a194"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading UniMiB-SHAR.zip file\n",
            "x/y_train shape  (4601, 151, 4) (4601,)\n",
            "x/y_validation shape  (1454, 151, 4) (1454,)\n",
            "x/y_test shape   (1524, 151, 4) (1524,)\n",
            "Number of classes: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuuSAE4DC7iS",
        "outputId": "0b782bd0-5ac9-4b1f-a1ca-aec5c95e77d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchinfo import summary\n",
        "import torch.quantization as quant\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "mZrgnYcXCuk5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "Y_train = torch.tensor(y_train, dtype=torch.int64)\n",
        "\n",
        "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
        "Y_valid = torch.tensor(y_valid, dtype=torch.int64)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "Y_test = torch.tensor(y_test, dtype=torch.int64)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "valid_dataset = TensorDataset(X_valid, Y_valid)\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, Y_test)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "4oKNfTFIDC4C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class TimeSeriesPatchEmbeddingLayer(nn.Module):\n",
        "    def __init__(self, in_channels, patch_size, embedding_dim, input_timesteps):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        # Calculate the number of patches, adjusting for padding if necessary\n",
        "        # Ceiling division to account for padding\n",
        "        self.num_patches = -(-input_timesteps // patch_size)\n",
        "        self.padding = (\n",
        "            self.num_patches * patch_size\n",
        "        ) - input_timesteps  # Calculate padding length\n",
        "\n",
        "        self.conv_layer = nn.Conv1d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=embedding_dim,\n",
        "            kernel_size=patch_size,\n",
        "            stride=patch_size,\n",
        "        )\n",
        "\n",
        "        self.class_token_embeddings = nn.Parameter(\n",
        "            torch.randn((1, 1, embedding_dim), requires_grad=True)\n",
        "        )\n",
        "        self.position_embeddings = PositionalEncoding(embedding_dim, dropout=0.1, max_len=input_timesteps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pad the input sequence if necessary\n",
        "        if self.padding > 0:\n",
        "            x = nn.functional.pad(x, (0, 0, 0, self.padding))  # Pad the second to last dimension, which is input_timesteps\n",
        "\n",
        "        # We use a Conv1d layer to generate the patch embeddings\n",
        "        x = x.permute(0, 2, 1)  # (batch, features, timesteps)\n",
        "        conv_output = self.conv_layer(x)\n",
        "        conv_output = conv_output.permute(0, 2, 1)  # (batch, timesteps, features)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        class_tokens = self.class_token_embeddings.expand(batch_size, -1, -1)\n",
        "        output = torch.cat((class_tokens, conv_output), dim=1)\n",
        "\n",
        "        output = self.position_embeddings(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def pos_encoding(self, q_len, d_model, normalize=True):\n",
        "        pe = torch.zeros(q_len, d_model)\n",
        "        position = torch.arange(0, q_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        if normalize:\n",
        "            pe = pe - pe.mean()\n",
        "            pe = pe / (pe.std() * 10)\n",
        "        return pe\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pos_encoding(q_len = x.size(1), d_model = x.size(2))\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "T6Job_-lDFDK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_instances, random_labels = next(iter(train_loader))\n",
        "random_instance = random_instances[0]\n",
        "\n",
        "BATCH_SIZE = random_instances.shape[0]\n",
        "TIMESTEPS = random_instance.shape[0]\n",
        "CHANNELS = random_instance.shape[1]\n",
        "PATCH_SIZE = 8\n",
        "\n",
        "patch_embedding_layer = TimeSeriesPatchEmbeddingLayer(\n",
        "    in_channels=CHANNELS,\n",
        "    patch_size=PATCH_SIZE,\n",
        "    embedding_dim=CHANNELS * PATCH_SIZE,\n",
        "    input_timesteps=TIMESTEPS,\n",
        ")\n",
        "\n",
        "patch_embeddings = patch_embedding_layer(random_instances)\n",
        "patch_embeddings.shape\n",
        "\n",
        "summary(\n",
        "    model=patch_embedding_layer,\n",
        "    # (batch_size, input_channels, input_timesteps)\n",
        "    input_size=(BATCH_SIZE, TIMESTEPS, CHANNELS),\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "    col_width=20,\n",
        "    row_settings=[\"var_names\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfx_fefRDIxg",
        "outputId": "0047b913-c2d9-4fb7-e7c3-b9f94b0c57b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type (var_name))                                           Input Shape          Output Shape         Param #              Trainable\n",
              "=================================================================================================================================================\n",
              "TimeSeriesPatchEmbeddingLayer (TimeSeriesPatchEmbeddingLayer)     [64, 151, 4]         [64, 20, 32]         32                   True\n",
              "├─Conv1d (conv_layer)                                             [64, 4, 152]         [64, 32, 19]         1,056                True\n",
              "├─PositionalEncoding (position_embeddings)                        [64, 20, 32]         [64, 20, 32]         --                   --\n",
              "│    └─Dropout (dropout)                                          [64, 20, 32]         [64, 20, 32]         --                   --\n",
              "=================================================================================================================================================\n",
              "Total params: 1,088\n",
              "Trainable params: 1,088\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.28\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.15\n",
              "Forward/backward pass size (MB): 0.31\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.47\n",
              "================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "class TimeSeriesTransformer(nn.Module):\n",
        "    def __init__(self, input_timesteps, in_channels, patch_size, embedding_dim, num_transformer_layers=6, num_heads=8, dim_feedforward=128, dropout=0.1, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.patch_embedding = TimeSeriesPatchEmbeddingLayer(in_channels, patch_size, embedding_dim, input_timesteps)\n",
        "\n",
        "        # Calculate the number of patches\n",
        "        self.num_patches = -(-input_timesteps // patch_size)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        # Setting batch_first=True to accommodate inputs with batch dimension first\n",
        "        encoder_layers = TransformerEncoderLayer(d_model=embedding_dim, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer=encoder_layers, num_layers=num_transformer_layers)\n",
        "\n",
        "        # Feedforward layer\n",
        "        self.ff_layer = nn.Linear(embedding_dim, dim_feedforward)\n",
        "        # Classifier Head\n",
        "        self.classifier = nn.Linear(dim_feedforward, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, in_channels, input_timesteps)\n",
        "\n",
        "        # Get patch embeddings\n",
        "        x = self.patch_embedding(x)  # Output shape: (batch_size, num_patches + 1, embedding_dim)\n",
        "\n",
        "        # Apply Transformer Encoder with batch first\n",
        "        x = self.transformer_encoder(x)  # Output shape: (batch_size, num_patches + 1, embedding_dim)\n",
        "\n",
        "        # Use the output corresponding to the class token for classification\n",
        "        class_token_output = x[:, 0, :]  # Select the class token for each item in the batch\n",
        "\n",
        "        # Feedforward layer\n",
        "        x = self.ff_layer(class_token_output)\n",
        "\n",
        "        # Classifier head\n",
        "        output = self.classifier(x)  # Output shape: (batch_size, num_classes)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "jiv86iUbDL3e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate the model\n",
        "model = TimeSeriesTransformer(\n",
        "    input_timesteps=TIMESTEPS,\n",
        "    in_channels=CHANNELS,\n",
        "    patch_size=4,\n",
        "    embedding_dim=32,\n",
        "    num_transformer_layers=12,\n",
        "    num_heads=16,\n",
        "    dim_feedforward=256,\n",
        "    dropout=0.2,\n",
        "    num_classes=n_classes,\n",
        ")\n",
        "\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the learning rate scheduler to reduce the learning rate by the specified step size and factor (gamma) every step_size epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
        "\n",
        "summary(\n",
        "    model=model,\n",
        "    input_size=(BATCH_SIZE, TIMESTEPS, CHANNELS),\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "    col_width=20,\n",
        "    row_settings=[\"var_names\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89MCYH4ZDOuT",
        "outputId": "02284cf0-738c-47ba-e0e7-ecb5771ede08"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=======================================================================================================================================\n",
              "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
              "=======================================================================================================================================\n",
              "TimeSeriesTransformer (TimeSeriesTransformer)           [64, 151, 4]         [64, 9]              --                   True\n",
              "├─TimeSeriesPatchEmbeddingLayer (patch_embedding)       [64, 151, 4]         [64, 39, 32]         32                   True\n",
              "│    └─Conv1d (conv_layer)                              [64, 4, 152]         [64, 32, 38]         544                  True\n",
              "│    └─PositionalEncoding (position_embeddings)         [64, 39, 32]         [64, 39, 32]         --                   --\n",
              "│    │    └─Dropout (dropout)                           [64, 39, 32]         [64, 39, 32]         --                   --\n",
              "├─TransformerEncoder (transformer_encoder)              [64, 39, 32]         [64, 39, 32]         --                   True\n",
              "│    └─ModuleList (layers)                              --                   --                   --                   True\n",
              "│    │    └─TransformerEncoderLayer (0)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (1)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (2)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (3)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (4)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (5)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (6)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (7)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (8)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (9)                 [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (10)                [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "│    │    └─TransformerEncoderLayer (11)                [64, 39, 32]         [64, 39, 32]         21,024               True\n",
              "├─Linear (ff_layer)                                     [64, 32]             [64, 256]            8,448                True\n",
              "├─Linear (classifier)                                   [64, 256]            [64, 9]              2,313                True\n",
              "=======================================================================================================================================\n",
              "Total params: 263,625\n",
              "Trainable params: 263,625\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 2.01\n",
              "=======================================================================================================================================\n",
              "Input size (MB): 0.15\n",
              "Forward/backward pass size (MB): 0.76\n",
              "Params size (MB): 0.05\n",
              "Estimated Total Size (MB): 0.96\n",
              "======================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, loss function, and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Number of epochs\n",
        "n_epochs = 20\n",
        "\n",
        "# Initialize variables for tracking the best model\n",
        "best_validation_acc = 0.0\n",
        "best_model_path = 'best_model_v2.pth'\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()  # Set model to training mode\n",
        "    train_losses = []\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "\n",
        "        predictions = model(inputs)  # Forward pass\n",
        "        loss = criterion(predictions, labels)  # Calculate loss\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Optimize\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Count the number of correct predictions\n",
        "        train_correct += (predictions.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = np.mean(train_losses)\n",
        "    train_acc = train_correct / total\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        validation_losses = []\n",
        "        validation_correct = 0\n",
        "        total_val = 0\n",
        "\n",
        "        for inputs, labels in valid_loader:\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            validation_losses.append(loss.item())\n",
        "\n",
        "            validation_correct += (predictions.argmax(1) == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        validation_loss = np.mean(validation_losses)\n",
        "        validation_acc = validation_correct / total_val\n",
        "\n",
        "    # Check if this is the best model so far\n",
        "    if validation_acc > best_validation_acc:\n",
        "        best_validation_acc = validation_acc\n",
        "        # Save the model\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f'Epoch {epoch+1}: New best model saved with validation accuracy: {validation_acc:.4f}')\n",
        "    end_time = time.time()\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {validation_loss:.4f}, Val Acc: {validation_acc:.4f}')\n",
        "    print(f\"Epoch {epoch+1} Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Loading the best model\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "print('Loaded best model for testing or further use.')\n",
        "print(f\"Original Model Training Time: {end_time - start_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymqOWnnbDQ3k",
        "outputId": "e97d5b2e-d059-439d-c2e5-b94cbf18b5d5"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: New best model saved with validation accuracy: 0.4659\n",
            "Epoch 1, Train Loss: 1.6500, Train Acc: 0.3875, Val Loss: 1.2996, Val Acc: 0.4659\n",
            "Epoch 1 Training Time: 44.64 seconds\n",
            "Epoch 2: New best model saved with validation accuracy: 0.4766\n",
            "Epoch 2, Train Loss: 1.2030, Train Acc: 0.5337, Val Loss: 1.4085, Val Acc: 0.4766\n",
            "Epoch 2 Training Time: 44.14 seconds\n",
            "Epoch 3, Train Loss: 1.1238, Train Acc: 0.5484, Val Loss: 1.3588, Val Acc: 0.4723\n",
            "Epoch 3 Training Time: 45.86 seconds\n",
            "Epoch 4, Train Loss: 1.0090, Train Acc: 0.5882, Val Loss: 1.4206, Val Acc: 0.4709\n",
            "Epoch 4 Training Time: 48.63 seconds\n",
            "Epoch 5, Train Loss: 0.9488, Train Acc: 0.6078, Val Loss: 1.5882, Val Acc: 0.4581\n",
            "Epoch 5 Training Time: 48.20 seconds\n",
            "Epoch 6: New best model saved with validation accuracy: 0.4851\n",
            "Epoch 6, Train Loss: 0.8711, Train Acc: 0.6334, Val Loss: 1.2605, Val Acc: 0.4851\n",
            "Epoch 6 Training Time: 45.58 seconds\n",
            "Epoch 7: New best model saved with validation accuracy: 0.5689\n",
            "Epoch 7, Train Loss: 0.8277, Train Acc: 0.6534, Val Loss: 1.0980, Val Acc: 0.5689\n",
            "Epoch 7 Training Time: 46.67 seconds\n",
            "Epoch 8, Train Loss: 0.8056, Train Acc: 0.6736, Val Loss: 1.3481, Val Acc: 0.5490\n",
            "Epoch 8 Training Time: 44.83 seconds\n",
            "Epoch 9: New best model saved with validation accuracy: 0.6264\n",
            "Epoch 9, Train Loss: 0.7383, Train Acc: 0.7027, Val Loss: 1.1958, Val Acc: 0.6264\n",
            "Epoch 9 Training Time: 46.38 seconds\n",
            "Epoch 10: New best model saved with validation accuracy: 0.6321\n",
            "Epoch 10, Train Loss: 0.6328, Train Acc: 0.7489, Val Loss: 1.2432, Val Acc: 0.6321\n",
            "Epoch 10 Training Time: 47.58 seconds\n",
            "Epoch 11: New best model saved with validation accuracy: 0.6662\n",
            "Epoch 11, Train Loss: 0.5839, Train Acc: 0.7731, Val Loss: 1.1171, Val Acc: 0.6662\n",
            "Epoch 11 Training Time: 48.28 seconds\n",
            "Epoch 12: New best model saved with validation accuracy: 0.6740\n",
            "Epoch 12, Train Loss: 0.5117, Train Acc: 0.8081, Val Loss: 1.1902, Val Acc: 0.6740\n",
            "Epoch 12 Training Time: 45.89 seconds\n",
            "Epoch 13: New best model saved with validation accuracy: 0.6818\n",
            "Epoch 13, Train Loss: 0.4883, Train Acc: 0.8154, Val Loss: 1.1712, Val Acc: 0.6818\n",
            "Epoch 13 Training Time: 46.76 seconds\n",
            "Epoch 14, Train Loss: 0.4533, Train Acc: 0.8246, Val Loss: 1.3621, Val Acc: 0.6278\n",
            "Epoch 14 Training Time: 46.33 seconds\n",
            "Epoch 15, Train Loss: 0.4141, Train Acc: 0.8402, Val Loss: 1.1663, Val Acc: 0.6797\n",
            "Epoch 15 Training Time: 47.53 seconds\n",
            "Epoch 16: New best model saved with validation accuracy: 0.7145\n",
            "Epoch 16, Train Loss: 0.4247, Train Acc: 0.8442, Val Loss: 0.9234, Val Acc: 0.7145\n",
            "Epoch 16 Training Time: 45.85 seconds\n",
            "Epoch 17, Train Loss: 0.4283, Train Acc: 0.8400, Val Loss: 0.9266, Val Acc: 0.6996\n",
            "Epoch 17 Training Time: 45.14 seconds\n",
            "Epoch 18, Train Loss: 0.3751, Train Acc: 0.8576, Val Loss: 1.2187, Val Acc: 0.6960\n",
            "Epoch 18 Training Time: 44.36 seconds\n",
            "Epoch 19: New best model saved with validation accuracy: 0.7202\n",
            "Epoch 19, Train Loss: 0.3750, Train Acc: 0.8559, Val Loss: 1.0510, Val Acc: 0.7202\n",
            "Epoch 19 Training Time: 45.11 seconds\n",
            "Epoch 20, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 1.2756, Val Acc: 0.7095\n",
            "Epoch 20 Training Time: 44.67 seconds\n",
            "Loaded best model for testing or further use.\n",
            "Original Model Training Time: 44.66993069648743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "import time\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    Y_pred_prob = model(X_test)\n",
        "\n",
        "Y_pred = Y_pred_prob.argmax(1)\n",
        "end_time = time.time()\n",
        "\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "confusion = confusion_matrix(Y_test, Y_pred)\n",
        "print(f\"Confusion matrix:\\n{confusion}\")\n",
        "print(f\"Original Model Average Inference Time: {end_time - start_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27-Xe3d2DdzD",
        "outputId": "ffa62d8a-3fc6-4f12-a349-8b009301ee81"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        34\n",
            "           1       0.51      0.74      0.61        47\n",
            "           2       0.72      0.96      0.82       344\n",
            "           3       0.96      0.83      0.89       413\n",
            "           4       0.82      0.66      0.73       184\n",
            "           5       0.80      0.96      0.87       146\n",
            "           6       0.83      0.66      0.73       256\n",
            "           7       0.42      0.31      0.36        68\n",
            "           8       0.30      0.56      0.39        32\n",
            "\n",
            "    accuracy                           0.77      1524\n",
            "   macro avg       0.59      0.63      0.60      1524\n",
            "weighted avg       0.78      0.77      0.76      1524\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0  24   0   0   0   0   0   8   2]\n",
            " [  1  35   0   0   0   0   0   8   3]\n",
            " [  0   0 330   6   8   0   0   0   0]\n",
            " [  0   0   7 341   3  36  26   0   0]\n",
            " [  0   0  53   2 121   0   8   0   0]\n",
            " [  0   0   0   6   0 140   0   0   0]\n",
            " [  0   0  71   1  16   0 168   0   0]\n",
            " [  2   8   0   0   0   0   0  21  37]\n",
            " [  0   1   0   0   0   0   0  13  18]]\n",
            "Original Model Average Inference Time: 7.419050216674805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define quantization configuration\n",
        "quant_config = quant.get_default_qconfig('qnnpack')\n",
        "\n",
        "# Apply post-training static quantization\n",
        "quant_model = quant.quantize_dynamic(\n",
        "    model, qconfig_spec={\"\": quant_config}, dtype=torch.qint8\n",
        ")"
      ],
      "metadata": {
        "id": "gkNMKGQ_DtXG"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define quantization configuration\n",
        "quant_config = quant.get_default_qconfig('qnnpack')\n",
        "\n",
        "# Apply dynamic quantization\n",
        "quant_model = quant.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")"
      ],
      "metadata": {
        "id": "l-wkC_xRW4X_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, loss function, and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Number of epochs\n",
        "n_epochs = 10\n",
        "\n",
        "# Initialize variables for tracking the best model\n",
        "best_validation_acc = 0.0\n",
        "best_model_path = 'best_model_v2.pth'\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    train_losses = []\n",
        "    train_correct = 0\n",
        "    total = 0\n",
        "\n",
        "# Validation loop\n",
        "    quant_model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        validation_losses = []\n",
        "        validation_correct = 0\n",
        "        total_val = 0\n",
        "\n",
        "        for inputs, labels in valid_loader:\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            validation_losses.append(loss.item())\n",
        "\n",
        "            validation_correct += (predictions.argmax(1) == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        validation_loss = np.mean(validation_losses)\n",
        "        validation_acc = validation_correct / total_val\n",
        "\n",
        "\n",
        "    # Check if this is the best model so far\n",
        "    if validation_acc > best_validation_acc:\n",
        "        best_validation_acc = validation_acc\n",
        "        # Save the model\n",
        "        torch.save(quant_model.state_dict(), best_model_path)\n",
        "        print(f'Epoch {epoch+1}: New best model saved with validation accuracy: {validation_acc:.4f}')\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {validation_loss:.4f}, Val Acc: {validation_acc:.4f}')\n",
        "\n",
        "# Loading the best model\n",
        "quant_model.load_state_dict(torch.load(best_model_path))\n",
        "print('Loaded best model for testing or further use.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4dv31znEgrT",
        "outputId": "d35e7d59-2d35-4400-e8c2-2625a11a33a3"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: New best model saved with validation accuracy: 0.7159\n",
            "Epoch 1, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9559, Val Acc: 0.7159\n",
            "Epoch 2: New best model saved with validation accuracy: 0.7195\n",
            "Epoch 2, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9715, Val Acc: 0.7195\n",
            "Epoch 3, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9775, Val Acc: 0.7180\n",
            "Epoch 4, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9686, Val Acc: 0.7095\n",
            "Epoch 5, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9776, Val Acc: 0.7060\n",
            "Epoch 6, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 1.0013, Val Acc: 0.7159\n",
            "Epoch 7, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9561, Val Acc: 0.7145\n",
            "Epoch 8, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9520, Val Acc: 0.7131\n",
            "Epoch 9, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9679, Val Acc: 0.7031\n",
            "Epoch 10, Train Loss: 0.3601, Train Acc: 0.8651, Val Loss: 0.9585, Val Acc: 0.7095\n",
            "Loaded best model for testing or further use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "start_time = time.time()\n",
        "quant_model.eval()\n",
        "with torch.no_grad():\n",
        "    Y_pred_prob = model(X_test)\n",
        "\n",
        "Y_pred = Y_pred_prob.argmax(1)\n",
        "end_time = time.time()\n",
        "\n",
        "print(classification_report(Y_test, Y_pred))\n",
        "confusion = confusion_matrix(Y_test, Y_pred)\n",
        "print(f\"Confusion matrix:\\n{confusion}\")\n",
        "print(f\"Quantized Model Average Inference Time: {end_time - start_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nagjMYNGFea6",
        "outputId": "240ca64a-9e7a-4b7a-9736-29d2bc1b1925"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        34\n",
            "           1       0.51      0.74      0.61        47\n",
            "           2       0.72      0.96      0.82       344\n",
            "           3       0.96      0.83      0.89       413\n",
            "           4       0.82      0.66      0.73       184\n",
            "           5       0.80      0.96      0.87       146\n",
            "           6       0.83      0.66      0.73       256\n",
            "           7       0.42      0.31      0.36        68\n",
            "           8       0.30      0.56      0.39        32\n",
            "\n",
            "    accuracy                           0.77      1524\n",
            "   macro avg       0.59      0.63      0.60      1524\n",
            "weighted avg       0.78      0.77      0.76      1524\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0  24   0   0   0   0   0   8   2]\n",
            " [  1  35   0   0   0   0   0   8   3]\n",
            " [  0   0 330   6   8   0   0   0   0]\n",
            " [  0   0   7 341   3  36  26   0   0]\n",
            " [  0   0  53   2 121   0   8   0   0]\n",
            " [  0   0   0   6   0 140   0   0   0]\n",
            " [  0   0  71   1  16   0 168   0   0]\n",
            " [  2   8   0   0   0   0   0  21  37]\n",
            " [  0   1   0   0   0   0   0  13  18]]\n",
            "Quantized Model Average Inference Time: 5.5719969272613525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prune the model\n",
        "prune_amount = 0.2\n",
        "prune_method = prune.L1Unstructured\n",
        "\n",
        "# Get the sequence length from the shape of your input data\n",
        "sequence_length = X_train.shape[1]\n",
        "\n",
        "# Define dummy input shape based on your data\n",
        "batch_size = X_train.shape[0]\n",
        "input_dim = X_train.shape[2]\n",
        "input_shape = (batch_size, sequence_length, input_dim)\n",
        "\n",
        "# Define the parameters to be pruned\n",
        "parameters_to_prune = [\n",
        "    (name, module) for name, module in model.named_parameters() if 'your_module_to_prune' in name\n",
        "]\n",
        "\n",
        "# Apply pruning to model\n",
        "for name, module in parameters_to_prune:\n",
        "    prune_method(module, amount=prune_amount)  # Prune based on L1 norm"
      ],
      "metadata": {
        "id": "ILMO0Kc8JDb7"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pruning method and amount\n",
        "import copy\n",
        "\n",
        "# Create a copy of the original model\n",
        "pruned_model = copy.deepcopy(model)\n",
        "\n",
        "# Prune the model\n",
        "prune_amount = 0.2\n",
        "prune_method = prune.L1Unstructured\n",
        "\n",
        "# Get the sequence length from the shape of your input data\n",
        "sequence_length = X_train.shape[1]\n",
        "\n",
        "# Define dummy input shape based on your data\n",
        "batch_size = X_train.shape[0]\n",
        "input_dim = X_train.shape[2]\n",
        "input_shape = (batch_size, sequence_length, input_dim)\n",
        "\n",
        "# Define the parameters to be pruned\n",
        "parameters_to_prune = [\n",
        "    (name, module) for name, module in model.named_parameters() if 'your_module_to_prune' in name\n",
        "]\n",
        "\n",
        "# Apply pruning to model\n",
        "for name, module in parameters_to_prune:\n",
        "    prune_method(module, amount=prune_amount)  # Prune based on L1 norm"
      ],
      "metadata": {
        "id": "hTZb7J5K9A-Z"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "# Create a copy of the original model\n",
        "pruned_model = copy.deepcopy(model)\n",
        "\n",
        "# Prune the model\n",
        "prune_amount = 0.2\n",
        "\n",
        "# Get the sequence length from the shape of your input data\n",
        "sequence_length = X_train.shape[1]\n",
        "\n",
        "# Define dummy input shape based on your data\n",
        "batch_size = X_train.shape[0]\n",
        "input_dim = X_train.shape[2]\n",
        "input_shape = (batch_size, sequence_length, input_dim)\n",
        "\n",
        "# Define the parameters to be pruned\n",
        "parameters_to_prune = [\n",
        "    (name, module) for name, module in model.named_parameters() if 'module_to_prune' in name\n",
        "]\n",
        "\n",
        "# Apply pruning to model\n",
        "for name, module in parameters_to_prune:\n",
        "    prune.ln_structured(module, name='weight', amount=prune_amount, n=2, dim=0)  # Prune based on L2 norm\n"
      ],
      "metadata": {
        "id": "Fp-hg7fbbZ4L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the pruned model\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    Y_pred_prob_pruned = pruned_model(X_test)\n",
        "\n",
        "Y_pred_pruned = Y_pred_prob_pruned.argmax(1)\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "print(\"Results for the pruned model:\")\n",
        "print(classification_report(Y_test, Y_pred_pruned))\n",
        "confusion_pruned = confusion_matrix(Y_test, Y_pred_pruned)\n",
        "print(f\"Confusion matrix for pruned model:\\n{confusion_pruned}\")\n",
        "print(f\"Pruned Model Average Inference Time: {end_time - start_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXwqJApoQ-VZ",
        "outputId": "04bae577-0893-49ab-a409-d750676cc899"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for the pruned model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.59      0.41        34\n",
            "           1       0.60      0.32      0.42        47\n",
            "           2       0.78      0.74      0.76       344\n",
            "           3       1.00      0.58      0.74       413\n",
            "           4       0.66      0.64      0.65       184\n",
            "           5       0.71      0.97      0.82       146\n",
            "           6       0.51      0.77      0.61       256\n",
            "           7       0.56      0.43      0.48        68\n",
            "           8       0.29      0.44      0.35        32\n",
            "\n",
            "    accuracy                           0.68      1524\n",
            "   macro avg       0.60      0.61      0.58      1524\n",
            "weighted avg       0.74      0.68      0.68      1524\n",
            "\n",
            "Confusion matrix for pruned model:\n",
            "[[ 20   6   0   0   0   0   0   4   4]\n",
            " [ 21  15   0   0   0   0   0   9   2]\n",
            " [  0   0 255   0  37   1  51   0   0]\n",
            " [  0   0   4 240   1  55 113   0   0]\n",
            " [  6   0  31   0 117   2  23   0   5]\n",
            " [  0   0   0   0   0 142   4   0   0]\n",
            " [  0   0  39   0  18   1 198   0   0]\n",
            " [ 11   2   0   0   3   0   0  29  23]\n",
            " [  6   2   0   0   0   0   0  10  14]]\n",
            "Pruned Model Average Inference Time: 4.804626941680908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Function to measure inference time\n",
        "def measure_inference_time(model, data):\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        _ = model(data)  # Perform inference\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time"
      ],
      "metadata": {
        "id": "IHLAib8jTOa2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom quantization configuration\n",
        "class CustomQuantConfig:\n",
        "    def __init__(self):\n",
        "        self.qconfig = torch.quantization.default_qconfig\n",
        "        self.qconfig_dict = {\"\": self.qconfig}\n",
        "\n",
        "    def get_quant_config(self):\n",
        "        return self.qconfig\n",
        "\n",
        "quant_config = CustomQuantConfig()\n",
        "\n",
        "# Apply post-training static quantization\n",
        "quant_model = quant.quantize_dynamic(\n",
        "    model, qconfig_spec=quant_config.qconfig_dict, dtype=torch.qint8\n",
        ")"
      ],
      "metadata": {
        "id": "9m0l6xIUq8qY"
      },
      "execution_count": 69,
      "outputs": []
    }
  ]
}