{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil  # https://docs.python.org/3/library/shutil.html\n",
        "from shutil import unpack_archive  # to unzip\n",
        "# from shutil import make_archive # to create zip for storage\n",
        "import requests  # for downloading zip file\n",
        "from scipy import io  # for loadmat, matlab conversion\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchinfo import summary\n",
        "\n",
        "# credit https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url\n",
        "# many other methods I tried failed to download the file properly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_url(url, save_path, chunk_size=128):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            fd.write(chunk)\n",
        "\n",
        "\n",
        "def unimib_load_dataset(\n",
        "        verbose=True,\n",
        "        incl_xyz_accel=False,  # include component accel_x/y/z in ____X data\n",
        "        # add rms value (total accel) of accel_x/y/z in ____X data\n",
        "        incl_rms_accel=True,\n",
        "        incl_val_group=False,  # True => returns x/y_test, x/y_validation, x/y_train\n",
        "    # False => combine test & validation groups\n",
        "        split_subj=dict\n",
        "    (train_subj=[4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 19, 20, 21, 22, 24, 26, 27, 29],\n",
        "     validation_subj=[1, 9, 16, 23, 25, 28],\n",
        "     test_subj=[2, 3, 13, 17, 18, 30]),\n",
        "        one_hot_encode=True):\n",
        "\n",
        "    # Download and unzip original dataset\n",
        "    if (not os.path.isfile('./UniMiB-SHAR.zip')):\n",
        "        print(\"Downloading UniMiB-SHAR.zip file\")\n",
        "        # invoking the shell command fails when exported to .py file\n",
        "        # redirect link https://www.dropbox.com/s/raw/x2fpfqj0bpf8ep6/UniMiB-SHAR.zip\n",
        "        #!wget https://www.dropbox.com/s/x2fpfqj0bpf8ep6/UniMiB-SHAR.zip\n",
        "        download_url(\n",
        "            'https://www.dropbox.com/s/raw/x2fpfqj0bpf8ep6/UniMiB-SHAR.zip', './UniMiB-SHAR.zip')\n",
        "    if (not os.path.isdir('./UniMiB-SHAR')):\n",
        "        shutil.unpack_archive('./UniMiB-SHAR.zip', '.', 'zip')\n",
        "    # Convert .mat files to numpy ndarrays\n",
        "    path_in = './UniMiB-SHAR/data'\n",
        "    # loadmat loads matlab files as dictionary, keys: header, version, globals, data\n",
        "    adl_data = io.loadmat(path_in + '/adl_data.mat')['adl_data']\n",
        "    adl_names = io.loadmat(path_in + '/adl_names.mat',\n",
        "                           chars_as_strings=True)['adl_names']\n",
        "    adl_labels = io.loadmat(path_in + '/adl_labels.mat')['adl_labels']\n",
        "\n",
        "    # Reshape data and compute total (rms) acceleration\n",
        "    num_samples = 151\n",
        "    # UniMiB SHAR has fixed size of 453 which is 151 accelX, 151 accely, 151 accelz\n",
        "    adl_data = np.reshape(adl_data, (-1, num_samples, 3),\n",
        "                          order='F')  # uses Fortran order\n",
        "    if (incl_rms_accel):\n",
        "        rms_accel = np.sqrt(\n",
        "            (adl_data[:, :, 0]**2) + (adl_data[:, :, 1]**2) + (adl_data[:, :, 2]**2))\n",
        "        adl_data = np.dstack((adl_data, rms_accel))\n",
        "\n",
        "    # remove component accel if needed\n",
        "    if (not incl_xyz_accel):\n",
        "        adl_data = np.delete(adl_data, [0, 1, 2], 2)\n",
        "\n",
        "    # matlab source was 1 indexed, change to 0 indexed\n",
        "    act_num = (adl_labels[:, 0])-1\n",
        "    sub_num = (adl_labels[:, 1])  # subject numbers are in column 1 of labels\n",
        "\n",
        "    if (not incl_val_group):\n",
        "        train_index = np.nonzero(np.isin(sub_num, split_subj['train_subj'] +\n",
        "                                         split_subj['validation_subj']))\n",
        "        x_train = adl_data[train_index]\n",
        "        y_train = act_num[train_index]\n",
        "    else:\n",
        "        train_index = np.nonzero(np.isin(sub_num, split_subj['train_subj']))\n",
        "        x_train = adl_data[train_index]\n",
        "        y_train = act_num[train_index]\n",
        "\n",
        "        validation_index = np.nonzero(\n",
        "            np.isin(sub_num, split_subj['validation_subj']))\n",
        "        x_validation = adl_data[validation_index]\n",
        "        y_validation = act_num[validation_index]\n",
        "\n",
        "    test_index = np.nonzero(np.isin(sub_num, split_subj['test_subj']))\n",
        "    x_test = adl_data[test_index]\n",
        "    y_test = act_num[test_index]\n",
        "\n",
        "    if (verbose):\n",
        "        print(\"x/y_train shape \", x_train.shape, y_train.shape)\n",
        "    if (incl_val_group):\n",
        "        print(\"x/y_validation shape \", x_validation.shape, y_validation.shape)\n",
        "    print(\"x/y_test shape  \", x_test.shape, y_test.shape)\n",
        "\n",
        "    if (incl_val_group):\n",
        "        return x_train, y_train, x_validation, y_validation, x_test, y_test\n",
        "    else:\n",
        "        return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading UniMiB-SHAR.zip file\n",
            "x/y_train shape  (4601, 151, 4) (4601,)\n",
            "x/y_validation shape  (1454, 151, 4) (1454,)\n",
            "x/y_test shape   (1524, 151, 4) (1524,)\n",
            "Number of classes: 9\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_valid, y_valid, X_test, y_test = unimib_load_dataset(\n",
        "    incl_xyz_accel=True, incl_val_group=True, one_hot_encode=False, verbose=True\n",
        ")\n",
        "\n",
        "# Number of classes\n",
        "n_classes = len(np.unique(y_train))\n",
        "print(f\"Number of classes: {n_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "Y_train = torch.tensor(y_train, dtype=torch.int64)\n",
        "\n",
        "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
        "Y_valid = torch.tensor(y_valid, dtype=torch.int64)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "Y_test = torch.tensor(y_test, dtype=torch.int64)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "valid_dataset = TensorDataset(X_valid, Y_valid)\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, Y_test)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
